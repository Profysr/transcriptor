{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper -q\n",
        "!apt install ffmpeg -y -q # -y for auto-yes to prompts\n",
        "!pip install yt-dlp -q\n",
        "!pip install gspread pandas -q # Ensure gspread and pandas are installed\n",
        "\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from pathlib import Path"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2y60Dvk2Fde",
        "outputId": "86066eac-27ba-4956-973b-1a3ed2dbf6c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_basic_segments(result):\n",
        "    \"\"\"\n",
        "    Extracts basic segment information (id, start, end, text) from Whisper's transcription result.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        {\n",
        "            \"id\": seg.get(\"id\"),\n",
        "            \"start\": seg.get(\"start\"),\n",
        "            \"end\": seg.get(\"end\"),\n",
        "            \"text\": seg.get(\"text\", \"\").strip(),\n",
        "        }\n",
        "        for seg in result.get(\"segments\", [])\n",
        "    ]\n",
        "\n",
        "def get_youtube_urls_from_sheet(spreadsheet_key: str) -> list:\n",
        "    \"\"\"\n",
        "    Authenticates with Google and retrieves YouTube URLs from a specified Google Sheet.\n",
        "\n",
        "    Args:\n",
        "        spreadsheet_key (str): The key of the Google Spreadsheet.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of YouTube URLs.\n",
        "    \"\"\"\n",
        "    print(\"Authenticating with Google Sheets...\")\n",
        "    try:\n",
        "        auth.authenticate_user()\n",
        "        creds, _ = default()\n",
        "        gc = gspread.authorize(creds)\n",
        "        spreadsheet = gc.open_by_key(spreadsheet_key)\n",
        "        worksheet = spreadsheet.get_worksheet(0) # Assuming URLs are in the first worksheet\n",
        "\n",
        "        # Get all values and convert to DataFrame\n",
        "        df = pd.DataFrame(worksheet.get_all_values())\n",
        "        if df.empty:\n",
        "            print(\"Error: Google Sheet is empty.\")\n",
        "            return []\n",
        "\n",
        "        # Assuming the first row is headers and 'youtube Url' is the column name\n",
        "        df.columns = df.iloc[0]\n",
        "        df = df.drop(0).reset_index(drop=True)\n",
        "\n",
        "        if \"youtube Url\" not in df.columns:\n",
        "            print(\"Error: 'youtube Url' column not found in Google Sheet.\")\n",
        "            return []\n",
        "\n",
        "        urls = df[\"youtube Url\"].dropna().tolist()\n",
        "        print(f\"Found {len(urls)} YouTube URLs in the spreadsheet.\")\n",
        "        return urls\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing Google Sheet: {e}\")\n",
        "        return []\n",
        "\n",
        "# --- 4. Function to Download Audio Directly from YouTube ---\n",
        "def download_audio(youtube_url: str, output_dir: Path) -> Path | None:\n",
        "    \"\"\"\n",
        "    Downloads the audio stream from a YouTube video directly to a WAV file.\n",
        "\n",
        "    Args:\n",
        "        youtube_url (str): The URL of the YouTube video.\n",
        "        output_dir (Path): The directory where the audio file will be saved.\n",
        "\n",
        "    Returns:\n",
        "        Path | None: The path to the downloaded WAV file, or None if download fails.\n",
        "    \"\"\"\n",
        "    # Sanitize URL for filename (yt_dlp usually handles this, but good for consistency)\n",
        "    # Get a safe title from yt_dlp info without downloading the whole thing yet\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL({'quiet': True, 'extract_flat': True, 'force_generic_extractor': True}) as ydl:\n",
        "            info = ydl.extract_info(youtube_url, download=False)\n",
        "            video_title = info.get('title', 'unknown_video')\n",
        "            # Simple regex to remove invalid characters for filenames\n",
        "            safe_title = re.sub(r'[^\\w\\-_.]', '_', video_title)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not get video title for {youtube_url}: {e}. Using generic name.\")\n",
        "        safe_title = \"unknown_video_\" + re.sub(r'[^\\w]', '', youtube_url)[:10] # Fallback\n",
        "\n",
        "    output_path = output_dir / f\"{safe_title}.wav\"\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best', # Prioritize best audio\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav', # Extract as WAV\n",
        "            'preferredquality': '192', # High quality audio\n",
        "        }],\n",
        "        'outtmpl': str(output_path.with_suffix('')), # Output template without extension, postprocessor adds it\n",
        "        'noplaylist': True, # Only download single video, not playlist\n",
        "        'quiet': True, # Suppress console output\n",
        "        'noprogress': True, # Suppress progress bar\n",
        "        'restrictfilenames': True, # Ensure safe filenames\n",
        "        'cookiefile': '/content/www.youtube.com_cookies.txt', # Use cookies if available\n",
        "    }\n",
        "\n",
        "    print(f\"Downloading audio for: {youtube_url}\")\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "        if output_path.exists():\n",
        "            print(f\"Successfully downloaded audio to: {output_path}\")\n",
        "            return output_path\n",
        "        else:\n",
        "            print(f\"Error: Audio file not found after download attempt for {youtube_url}.\")\n",
        "            return None\n",
        "    except yt_dlp.utils.DownloadError as e:\n",
        "        print(f\"Error downloading audio from {youtube_url}: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during audio download for {youtube_url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- 5. Function to Transcribe Audio with Whisper ---\n",
        "def transcribe_audio(audio_path: Path, whisper_model) -> list | None:\n",
        "    \"\"\"\n",
        "    Transcribes an audio file using the loaded Whisper model.\n",
        "\n",
        "    Args:\n",
        "        audio_path (Path): The path to the audio file.\n",
        "        whisper_model: The loaded Whisper model instance.\n",
        "\n",
        "    Returns:\n",
        "        list | None: A list of transcription segments, or None if transcription fails.\n",
        "    \"\"\"\n",
        "    print(f\"Transcribing audio: {audio_path}\")\n",
        "    try:\n",
        "        # Using verbose=False to suppress detailed transcription logs unless needed\n",
        "        result = whisper_model.transcribe(str(audio_path), verbose=False, temperature=0.4, condition_on_previous_text=True)\n",
        "        segments = extract_basic_segments(result)\n",
        "        print(f\"Transcription complete for: {audio_path}\")\n",
        "        return segments\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing {audio_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- 6. Function to Save Transcription to JSON ---\n",
        "def save_transcription_to_json(segments: list, output_dir: Path, original_filename: str):\n",
        "    \"\"\"\n",
        "    Saves transcription segments to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        segments (list): The list of transcription segments.\n",
        "        output_dir (Path): The directory where the JSON file will be saved.\n",
        "        original_filename (str): The original filename (e.g., video title) to base the JSON filename on.\n",
        "    \"\"\"\n",
        "    json_filename = output_dir / f\"{Path(original_filename).stem}_segments.json\"\n",
        "    print(f\"Saving segments to: {json_filename}\")\n",
        "\n",
        "    data_to_save = {\n",
        "        \"filename\": f\"{Path(original_filename).stem}\",\n",
        "        \"segments\": segments\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(data_to_save, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"Successfully saved segments to {json_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving segments to {json_filename}: {e}\")"
      ],
      "metadata": {
        "id": "sCvajskL2SE3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Main Workflow Execution ---\n",
        "def main_workflow(spreadsheet_key: str, audio_output_folder: str = \"/content/audioFiles\", transcription_output_folder: str = \"/content/subtitles\"):\n",
        "    \"\"\"\n",
        "    Orchestrates the entire process: fetches URLs, downloads audio, transcribes, and saves.\n",
        "\n",
        "    Args:\n",
        "        spreadsheet_key (str): The key of the Google Spreadsheet containing YouTube URLs.\n",
        "        audio_output_folder (str): Directory to save temporary audio files.\n",
        "        transcription_output_folder (str): Directory to save final JSON transcriptions.\n",
        "    \"\"\"\n",
        "    # Create output directories if they don't exist\n",
        "    audio_dir = Path(audio_output_folder)\n",
        "    transcription_dir = Path(transcription_output_folder)\n",
        "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
        "    transcription_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Load Whisper model once\n",
        "    print(\"Loading Whisper model (turbo)... This may take a moment.\")\n",
        "    try:\n",
        "        # Note: \"turbo\" is not a standard Whisper model size. Assuming it's a custom\n",
        "        # or a very small/fast model. Standard sizes are 'tiny', 'base', 'small', 'medium', 'large'.\n",
        "        # If 'turbo' fails, try 'base' or 'small'.\n",
        "        whisper_model = whisper.load_model(\"base\", download_root=\"/content/Data/Models\")\n",
        "        print(\"Whisper model loaded.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Whisper model: {e}. Please check model name or internet connection.\")\n",
        "        return\n",
        "\n",
        "    youtube_urls = get_youtube_urls_from_sheet(spreadsheet_key)\n",
        "\n",
        "    if not youtube_urls:\n",
        "        print(\"No YouTube URLs to process. Exiting.\")\n",
        "        return\n",
        "\n",
        "    for i, url in enumerate(youtube_urls):\n",
        "        print(f\"\\n--- Processing video {i+1}/{len(youtube_urls)}: {url} ---\")\n",
        "        audio_file_path = None # Initialize to None\n",
        "\n",
        "        try:\n",
        "            # Step 1: Download audio directly\n",
        "            audio_file_path = download_audio(url, audio_dir)\n",
        "            if audio_file_path is None:\n",
        "                print(f\"Skipping transcription for {url} due to download failure.\")\n",
        "                continue\n",
        "\n",
        "            # Step 2: Transcribe audio\n",
        "            segments = transcribe_audio(audio_file_path, whisper_model)\n",
        "            if segments is None:\n",
        "                print(f\"Skipping saving for {url} due to transcription failure.\")\n",
        "                continue\n",
        "\n",
        "            # Step 3: Save transcription to JSON\n",
        "            # Use the stem of the audio file name as the base for the JSON file name\n",
        "            save_transcription_to_json(segments, transcription_dir, audio_file_path.name)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during processing of {url}: {e}\")\n",
        "        finally:\n",
        "            # Step 4: Clean up temporary audio file\n",
        "            if audio_file_path and audio_file_path.exists():\n",
        "                try:\n",
        "                    os.remove(audio_file_path)\n",
        "                    print(f\"Cleaned up temporary audio file: {audio_file_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error cleaning up {audio_file_path}: {e}\")\n",
        "\n",
        "    print(\"\\n--- All videos processed ---\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "if __name__ == \"__main__\":\n",
        "    # IMPORTANT: Replace with your actual Google Sheet key\n",
        "    # This key is from the original notebook: '1-gartYfd6OXdtw64O6ZxbVuxznH-D5vSydyf7_k7j_M'\n",
        "    # Ensure your Google Sheet is publicly accessible or you have given permissions to the service account.\n",
        "    # Also, ensure the first column is named \"youtube Url\"\n",
        "    YOUR_GOOGLE_SHEET_KEY = '1-gartYfd6OXdtw64O6ZxbVuxznH-D5vSydyf7_k7j_M'\n",
        "\n",
        "    main_workflow(YOUR_GOOGLE_SHEET_KEY)\n",
        "\n",
        "    # You can now proceed to load the generated JSON files from /content/subtitles\n",
        "    # and use them with your Gemini API call as discussed previously."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuU7Uixh2e7U",
        "outputId": "9d1a610a-662f-4846-e0ae-c9ab340ea41e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model (turbo)... This may take a moment.\n",
            "Whisper model loaded.\n",
            "Authenticating with Google Sheets...\n",
            "Found 2 YouTube URLs in the spreadsheet.\n",
            "\n",
            "--- Processing video 1/2: https://www.youtube.com/watch?v=FFH3uQDk2yU ---\n",
            "Downloading audio for: https://www.youtube.com/watch?v=FFH3uQDk2yU\n",
            "Successfully downloaded audio to: /content/audioFiles/Build_Anything_With_Grok_4_and_n8n_AI_Agents.wav\n",
            "Transcribing audio: /content/audioFiles/Build_Anything_With_Grok_4_and_n8n_AI_Agents.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63280/63280 [00:38<00:00, 1647.52frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription complete for: /content/audioFiles/Build_Anything_With_Grok_4_and_n8n_AI_Agents.wav\n",
            "Saving segments to: /content/subtitles/Build_Anything_With_Grok_4_and_n8n_AI_Agents_segments.json\n",
            "Successfully saved segments to /content/subtitles/Build_Anything_With_Grok_4_and_n8n_AI_Agents_segments.json\n",
            "Cleaned up temporary audio file: /content/audioFiles/Build_Anything_With_Grok_4_and_n8n_AI_Agents.wav\n",
            "\n",
            "--- Processing video 2/2: https://www.youtube.com/watch?v=foEW387Y4rU ---\n",
            "Downloading audio for: https://www.youtube.com/watch?v=foEW387Y4rU\n",
            "Successfully downloaded audio to: /content/audioFiles/Someone_Will_Get_Really_Rich_Doing_This.wav\n",
            "Transcribing audio: /content/audioFiles/Someone_Will_Get_Really_Rich_Doing_This.wav\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40320/40320 [00:15<00:00, 2570.00frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription complete for: /content/audioFiles/Someone_Will_Get_Really_Rich_Doing_This.wav\n",
            "Saving segments to: /content/subtitles/Someone_Will_Get_Really_Rich_Doing_This_segments.json\n",
            "Successfully saved segments to /content/subtitles/Someone_Will_Get_Really_Rich_Doing_This_segments.json\n",
            "Cleaned up temporary audio file: /content/audioFiles/Someone_Will_Get_Really_Rich_Doing_This.wav\n",
            "\n",
            "--- All videos processed ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}